
<!doctype html>
<html lang="en">
<head>

<!-- all praise to https://realfavicongenerator.net -->
<link rel="icon" href="/favicon.ico?v=2" /> <!-- force refresh -->
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="/fonts.css">
  <link rel="stylesheet" href="/4ed/pbrstyle.css">
  <link rel="stylesheet" href="/fontawesome-free-5.15.3-web/css/all.css">

  <script async src="https://cse.google.com/cse.js?cx=003601324460585362024:4xwpwgaitgd"></script>
  <script src="/react.min.js"></script>
  <script src="/react-dom.min.js"></script>
  <script src="/jeri.min.js"></script>
  <link rel="preload" href="/exr.worker.js" as="script" crossorigin="anonymous">
        
  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="/bootstrap.min.css">

  <title>Preface</title>
</head>
        
<body>

<nav class="fixed-top-lg-navbar navbar navbar-expand bg-light navbar-light">
  <ul class="nav navbar-nav">
    <a class="navbar-brand" href="/4ed/contents.html"><img src="/4ed/pbr.jpg" width=25 height=25></a>
    <li class="nav-item"><a class="nav-link" href="contents.html">Physically Based Rendering: </a></li>
    <li class="nav-item"><a class="nav-link" href="#">Preface</a></li>
  </ul>

  <ul class="nav navbar-nav ml-auto d-none d-md-block">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
  <ul class="nav navbar-nav d-block d-md-none">
        <li class="nav-item"><div class="gcse-search"></div></li>
    </ul>
</nav>

<div class="maincontainer">
<div class="container-fluid">

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link "></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h1> Preface</h1><p>


</p>
<p> <em>[Just as] other information
should be available to those who want to
learn and understand, program source code is the only means for programmers
to learn the art from their predecessors. It would be unthinkable for
playwrights not to allow other playwrights to read their plays [or to
allow them] at theater performances where they would be barred even from
taking notes. Likewise, any good author is well read, as every child who
learns to write will read hundreds of times more than it
writes. Programmers, however, are expected to invent the alphabet and learn
to write long novels all on their own. Programming cannot grow and learn
unless the next generation of programmers has access to the knowledge and
information gathered by other programmers before them.</em>&nbsp;
&mdash;Erik Naggum

</p>
<p>

</p>
<p> Rendering is a fundamental component of computer graphics. At
the highest
level of abstraction, rendering is the process of converting a
description of a three-dimensional scene into an image.  Algorithms for
animation, geometric modeling, texturing, and other areas of computer
graphics all must pass their results through some sort of rendering process
so that they can be made visible in an image.  Rendering
has become ubiquitous; from movies to games and beyond, it has opened new
frontiers for creative expression, entertainment, and visualization.

</p>
<p>In the early years of the field, research in rendering focused on solving
fundamental problems such as determining which objects are visible from a
given viewpoint.  As effective solutions to these problems have been found and
as richer and more realistic scene descriptions have
become available thanks to
continued progress in other areas of graphics, modern rendering has grown
to include ideas from a broad range of disciplines, including physics
and astrophysics, astronomy, biology, psychology and the study of
perception, and pure and applied mathematics.  The interdisciplinary nature
of rendering is one of the reasons that it is such a fascinating area of
study.

</p>
<p>This book presents a selection of modern rendering algorithms through the
documented source code for a complete rendering system. Nearly all of the images
in this book, including the one on the front cover, were
rendered by this software.  All of the algorithms that came together to
generate these images are described in these pages.  The system,
<tt>pbrt</tt>, is written using a programming methodology called <em>literate
programming</em> that mixes prose describing the system with the source code
that implements it.  We believe that the literate programming approach is a
valuable way to introduce ideas in computer graphics and computer science
in general.  Often, some of the subtleties of an algorithm can be unclear
or hidden until it is implemented, so seeing an actual implementation is a
good way to acquire a solid understanding of that algorithm&rsquo;s details.
Indeed, we believe that deep understanding of a number of carefully selected algorithms
in this manner provides a better foundation for further study of computer
graphics than does superficial understanding of many.

</p>
<p>In addition to clarifying how an algorithm is implemented in practice,
presenting these algorithms in the context of a complete and nontrivial
software system also allows us to address issues in the design and
implementation of medium-sized rendering systems.  The design of a
rendering system&rsquo;s basic abstractions and interfaces has substantial
implications for both the elegance of the implementation and the ability to
extend it later, yet the trade-offs in this design space are rarely
discussed.

</p>
<p><tt>pbrt</tt> and the contents of this book focus exclusively on <em>photorealistic
rendering</em>, which can be defined variously as the task of generating images
that are indistinguishable from those that a camera would capture in a
photograph or as the task of generating images that evoke
the same response from a human observer as 
looking at the actual scene.  There are many reasons to focus on
photorealism.  Photorealistic images are crucial for 
special effects in movies because computer-generated imagery
must often be mixed seamlessly with footage of the real world.
In applications like computer games where all of the imagery is synthetic,
photorealism is an effective tool for making the observer forget that he or
she is looking at an environment that does not actually exist.  Finally,
photorealism gives a reasonably well-defined metric for evaluating the
quality of the rendering system&rsquo;s output.

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Audience</h3><p>


</p>
<p> There are three main audiences that this book is intended for.
The first is students in graduate or upper-level undergraduate computer
graphics classes.  This book assumes existing knowledge of computer
graphics at the level of an introductory college-level course, although
certain key concepts such as basic vector geometry and transformations will
be reviewed here.  For students who do not have experience with programs
that have tens of thousands of lines of source code, the literate
programming style gives a gentle introduction to this complexity.  We pay
special attention to explaining the reasoning behind some of the key
interfaces and abstractions in the system in order to give these readers a
sense of why the system is structured in the way that it&nbsp;is.

</p>
<p>The second audience is advanced graduate students and researchers in
computer graphics. For those doing research in rendering, the book provides
a broad introduction to the area, and the <tt>pbrt</tt> source code provides a
foundation that can be useful to build upon (or at least to use bits of
source code from).  For those working in other areas of computer graphics, we believe that
having a thorough understanding of rendering can be helpful context to
carry along.

</p>
<p>Our final audience is software developers in industry.  Although many of the
basic ideas in this book will be familiar to this audience, seeing
explanations of the algorithms presented in the literate style may lead to
new perspectives. <tt>pbrt</tt> also includes carefully crafted and debugged implementations of
many algorithms that can be challenging to implement correctly; these
should be of particular interest to experienced
practitioners in rendering.  We hope that delving into one particular
organization of a complete and nontrivial rendering system will also be thought
provoking to this audience.

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Overview and Goals</h3><p>


</p>
<p><tt>pbrt</tt> is based on the <em>ray-tracing</em> algorithm.  Ray tracing is an
elegant technique that has its origins in lens making; Carl Friedrich
Gau&szlig; traced rays through lenses by hand in the 19th century.
Ray-tracing algorithms on computers follow the path of infinitesimal rays
of light through the scene until they intersect a surface.  This approach
gives a simple method for finding the first visible object as seen from any
particular position and direction and is the basis for many rendering
algorithms.

</p>
<p><tt>pbrt</tt> was designed and implemented with three main goals in mind: it should
be <em>complete</em>, it should be <em>illustrative</em>, and it should be
<em>physically based</em>.

</p>
<p>Completeness implies that the system should not lack key features found in
high-quality commercial rendering systems.  In particular, it means that
important practical issues, such as antialiasing, robustness, numerical
precision, and the
ability to efficiently render complex scenes should all be addressed
thoroughly.  It is important to consider these issues from the start of the
system&rsquo;s design, since these features can have subtle implications for all
components of the system and can be quite difficult to retrofit into the
system at a later stage of implementation.

</p>
<p>Our second goal means that we tried to choose algorithms, data structures,
and rendering techniques with care and with an eye toward readability and
clarity.  Since their implementations will be examined by more readers
than is the case for other rendering systems, we tried to select the
most elegant algorithms that we were aware of and implement them as well as
possible.  This goal also required that the system be small enough for a
single person to understand completely.  We have implemented <tt>pbrt</tt> using an
extensible architecture, with the core of the system implemented in
terms of a set of carefully designed interface classes, and as much of
the specific functionality as possible in implementations of these
interfaces. The result is that one
does not need to understand all of the specific implementations in order to
understand the basic structure of the system.  This makes it easier to
delve deeply into parts of interest and skip others, without losing sight
of how the overall system fits together.

</p>
<p>There is a tension between the two goals of being complete and being
illustrative.  Implementing and describing every possible useful technique
would not only make this book unacceptably long, but would also make the
system prohibitively complex for most readers.  In cases where <tt>pbrt</tt> lacks
a particularly useful feature, we have attempted to design the architecture
so that the feature could be added without altering the overall system
design.

</p>
<p>The basic foundations for physically based rendering are the laws of
physics and their mathematical expression.  <tt>pbrt</tt> was designed to use the
correct physical units and concepts for the quantities it computes and the
algorithms it implements.  <tt>pbrt</tt> strives to compute
images that are <em>physically correct</em>; they accurately reflect the
lighting as it would be in a real-world version of the scene.<button style="button" data-toggle="tooltip" data-placement="right" data-html="true" class="btn footnote-button" title="Of
course, any computer simulation of physics requires carefully choosing
approximations that trade off requirements for fidelity with computational
efficiency.  See Section&nbsp;<a href="Introduction/Photorealistic_Rendering_and_the_Ray-Tracing_Algorithm.html#sec:photorealistic-rendering-context">1.2</a> for
further discussion of the choices made in <tt>pbrt</tt>.">
      <sup>&dagger;</sup>
    </button>
		
One
advantage of the decision to use a physical basis is that it gives a
concrete standard of program correctness: for simple scenes, where the
expected result can be computed in closed form, if <tt>pbrt</tt> does not compute
the same result, we know there must be a bug in the implementation.
Similarly, if different physically based lighting algorithms in <tt>pbrt</tt> give
different results for the same scene, or if
<tt>pbrt</tt> does not give the same results as another physically based renderer,
there is certainly an error in one of them.  Finally, we believe that this
physically based approach to rendering is valuable because it is rigorous.
When it is not clear how a particular computation should be performed,
physics gives an answer that guarantees a consistent result.

</p>
<p>Efficiency was given lower priority than these three goals.  Since
rendering systems often run for many minutes or hours in the course of
generating an image, efficiency is clearly important.  However, we have
mostly confined ourselves to <em>algorithmic</em> efficiency rather than
low-level code optimization.  In some cases, obvious micro-optimizations
take a backseat to clear, well-organized code, although we did make some
effort to optimize the parts of the system where most of the computation
occurs.

</p>
<p>In the course of presenting <tt>pbrt</tt> and discussing its implementation, we
hope to convey some hard-learned lessons from years of rendering research
and development.  There is more to writing a good renderer than stringing
together a set of fast algorithms; making the system both flexible and
robust is a difficult task.  The system&rsquo;s performance must degrade
gracefully as more geometry or light sources are added to it or as any
other axis of complexity is stressed.

</p>
<p>The rewards for developing a system that addresses all these issues are
enormous&mdash;it is a great pleasure to write a new renderer or add a new
feature to an existing renderer and use it to create an image that could not
be generated before.  Our most fundamental goal in writing this book was to
bring this opportunity to a wider audience.  Readers are encouraged to use
the system to render the example scenes in the <tt>pbrt</tt> software distribution
as they progress through the book.  Exercises at the end of each chapter suggest
modifications to the system that will help clarify its inner workings and
more complex projects to extend the system by adding new features.

</p>
<p>The website for this book is located at <a href="http://pbrt.org">pbrt.org</a>.  This site
includes links to the <tt>pbrt</tt> source code, scenes that can be downloaded to
render with <tt>pbrt</tt>, and a bug tracker, as well as errata.  Any
errors in this text that are not listed in the errata
can be reported to the email address <em>authors@pbrt.org</em>.  We greatly
value your feedback!

</p>
<p>

</p>
<p>


</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Changes Between The First and Second Editions</h3><p>



</p>
<p>Six years passed between the publication of the first edition of this book
in 2004 and the second edition in 2010.
In that time, thousands of copies of the book were sold, and the <tt>pbrt</tt> software was downloaded thousands of times from the book&rsquo;s website.
The <tt>pbrt</tt> user base gave us a significant amount of feedback and
encouragement, and
our experience with the system guided many of the decisions we made in making
changes between the version of <tt>pbrt</tt> presented in the first edition and the
version in the second edition.  In addition to a number of bug fixes, we also
made several significant design changes and enhancements:

</p>
<p></p>
<ul>
<li> <em>Removal of the plugin architecture:</em>  The first version of <tt>pbrt</tt> used a
runtime plugin architecture to dynamically load code for implementations
of objects like shapes, lights, integrators, cameras, and other objects
that were used in the scene currently being rendered.  This approach
allowed users to extend <tt>pbrt</tt> with new object types (e.g., new shape
primitives) without recompiling the entire rendering system.  This approach
initially seemed elegant, but it complicated the task of
supporting <tt>pbrt</tt> on multiple platforms and it made debugging more difficult.
The only new usage scenario that it truly enabled (binary-only
distributions of <tt>pbrt</tt> or binary plugins) was actually contrary to our
pedagogical and open-source goals.  Therefore, the plugin architecture was
dropped in this edition.

<li> <em>Removal of the image-processing pipeline:</em>  The first version of <tt>pbrt</tt> provided a tone-mapping interface that converted high-dynamic-range (HDR)
floating-point output images directly into low-dynamic-range TIFFs for
display.  This functionality made sense in 2004, as support for HDR images
was still sparse.  In 2010, however, advances in digital photography had
made HDR images commonplace.  Although the theory and practice of tone mapping are
elegant and worth learning, we decided to focus the new book exclusively on
the process of image formation and skip the topic of image display.
Interested readers should consult the book written
by Reinhard et al. (<a href="Preface/Further_Reading.html#cite:Reinhard10">2010</a>) for a
thorough and modern treatment of the HDR image display process.

<li> <em>Task parallelism:</em>  Multicore architectures became ubiquitous, and we
felt that <tt>pbrt</tt> would not remain relevant without the ability to scale to
the number of locally available cores.  We also hoped that the parallel
programming implementation details documented in this book would help
graphics programmers understand some of the subtleties and complexities in
writing scalable parallel code. 

<li> <em>Appropriateness for &ldquo;production&rdquo; rendering:</em>  The first version of
<tt>pbrt</tt> was intended exclusively as a pedagogical tool and a stepping-stone
for rendering research.  Indeed, we made a number of decisions in preparing
the first edition that were contrary to use in a production environment,
such as limited support for image-based lighting, no support for motion
blur, and a photon mapping implementation that was not robust in the
presence of complex lighting.  With much improved support for these
features as well as support for subsurface scattering and Metropolis light
transport, we feel that with the second edition, <tt>pbrt</tt> became much more
suitable for rendering very high-quality images of complex environments.
</ul><p>


</p>
<p>

</p>
<p>


</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Changes Between The Second and Third Editions</h3><p>



</p>
<p>With the passage of another six years, it was time to update and extend the
book and the <tt>pbrt</tt> system. We continued to learn from readers&rsquo; and users&rsquo;
experiences to better understand which topics were most useful to cover.
Further, rendering research continued apace; many parts of the book were
due for an update to reflect current best practices.  We made significant
improvements on a number of fronts:

</p>
<p></p>
<ul>
<li> <em>Bidirectional light transport:</em> The third version of <tt>pbrt</tt> added
a bidirectional path tracer, including full support for
volumetric light transport and multiple importance
sampling to weight paths. An all-new Metropolis light transport
integrator used components of the bidirectional path tracer, allowing
for a particularly succinct implementation of that algorithm.

<li> <em>Subsurface scattering:</em> The appearance of many objects&mdash;notably, skin
and translucent objects&mdash;is a result of subsurface light transport. Our
implementation of subsurface scattering in the second edition reflected the
state of the art in the early 2000s; we thoroughly updated both BSSRDF
models and our subsurface light transport algorithms to reflect the
progress made in ten subsequent years of research.

<li> <em>Numerically robust intersections:</em> The effects of floating-point
round-off error in geometric ray intersection calculations have been a
long-standing challenge in ray tracing: they can cause small errors to be
present throughout the image. We focused on this issue and derived
conservative (but tight) bounds of this error, which made our
implementation more robust to this issue than previous rendering systems.

<li> <em>Participating media representation:</em> We significantly improved
the way that scattering media are described and represented in the
system; this allows for more accurate results with nested scattering media.
A new sampling technique enabled unbiased rendering of heterogeneous media
in a way that cleanly integrated with all of the other parts of the system.

<li> <em>Measured materials:</em> This edition added a new technique to represent
and evaluate measured materials using a sparse frequency-space basis. This
approach is convenient because it allows for exact importance sampling, which
was not possible with the representation used in the previous edition.

<li> <em>Photon mapping:</em> A significant step forward for photon mapping
algorithms has been the development of variants that do not require storing
all of the photons in memory. We replaced <tt>pbrt</tt>&rsquo;s photon mapping
algorithm with an implementation based on stochastic progressive photon
mapping, which efficiently renders many difficult light transport effects.

<li> <em>Sample generation algorithms:</em> The distribution of sample values used
for numerical integration in rendering algorithms can have a surprisingly
large effect on the quality of the final results. We thoroughly
updated our treatment of this topic, covering new approaches and efficient
implementation techniques in more depth than before. 
</ul><p>


</p>
<p>Many other parts of the system were improved and updated to reflect
progress in the field: microfacet reflection models were treated in more
depth, with much better sampling techniques; a new &ldquo;curve&rdquo; shape was
added for modeling hair and other fine geometry; and a new camera model
that simulates realistic lens systems was made available. Throughout the
book, we made numerous smaller changes to more clearly explain and
illustrate the key concepts in physically based rendering systems
like <tt>pbrt</tt>.

</p>
<p>

</p>
<p>


</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Changes Between The Third and Fourth Editions</h3><p>



</p>
<p>Innovation in rendering algorithms has shown no sign of slowing down, and so
in 2019 we began focused work on a fourth edition of the text.  Not only
does almost every chapter include substantial additions, but we have
updated the order of chapters and ideas introduced, bringing Monte Carlo
integration and the basic ideas of path tracing to the fore
rather than saving them for the end.

</p>
<p>Capabilities of the system that have seen especially significant
improvements include:

</p>
<p></p>
<ul>
<li> <em>Volumetric scattering:</em>  We have updated the algorithms that model
scattering from participating media to the state of the art, adding support
for emissive volumes, efficient sampling of volumes with varying densities,
and robust support for chromatic media, where the scattering properties
vary by wavelength.

<li> <em>Spectral rendering:</em> We have excised all use of RGB color for lighting
calculations; <tt>pbrt</tt> now performs lighting calculations exclusively in
terms of samples of wavelength-dependent spectral distributions.  Not only
is this approach more physically accurate than using RGB, but it also allows
<tt>pbrt</tt> to accurately model effects like dispersion.

<li> <em>Reflection models:</em> Our coverage of the foundations of BSDFs and
reflection models has been extensively revised, and we have expanded the
range of BSDFs covered to include one that accurately models
reflection from hair and another that models scattering from layered
materials.
The measured BRDF follows a new approach that can represent a wide
set of materials&rsquo; reflection spectra.

<li> <em>Light sampling:</em> Not only have we improved the algorithms for sampling
points on individual light sources to better reflect the state of the art,
but this edition also includes support for <em>many-light sampling</em>,
which makes it possible to efficiently render scenes with thousands or
millions of light sources by carefully sampling just a few of them.

<li> <em>GPU rendering:</em> This version of <tt>pbrt</tt> adds support for rendering on
GPUs, which can provide 10&ndash;100 times higher ray tracing performance
than CPUs.  We have implemented this capability in a way so that almost all
of the code presented in the book runs on both CPUs and GPUs, which has made
it possible to localize discussion of GPU-related issues to
Chapter&nbsp;<a href="Wavefront_Rendering_on_GPUs.html#chap:gpu">15</a>.
</ul><p>


</p>
<p>The system has seen numerous other improvements and additions, including a
new bilinear patch shape, many updates to the sample-generation algorithms
that are at the heart of Monte Carlo integration, support for
outputting auxiliary information at each pixel about the visible surface
geometry and reflection properties, and many more small improvements to the
system.

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>Acknowledgments</h3><p>


</p>
<p> Pat Hanrahan has contributed to this book in more ways than we
could hope to acknowledge; we owe a profound debt to him.  He tirelessly
argued for clean interfaces and finding the right abstractions to use
throughout the system, and his understanding of and approach to rendering
deeply influenced its design.  His willingness to use <tt>pbrt</tt> and this
manuscript in his rendering course at Stanford was enormously helpful,
particularly in the early years of its life when it was still in very rough
form; his feedback throughout this process has been crucial for bringing
the text to its current state.  Finally, the group of people that Pat
helped assemble at the Stanford Graphics Lab, and the open environment that
he fostered, made for an exciting, stimulating, and fertile environment.
Matt and Greg both feel extremely privileged to have been there.

</p>
<p>We owe a debt of gratitude to the many students who used early drafts of
this book in courses at Stanford and the University of Virginia between
1999 and 2004.  These students provided an enormous amount of feedback
about the book and <tt>pbrt</tt>.  The teaching assistants for these courses
deserve special mention: Tim Purcell, Mike Cammarano, Ian Buck, and Ren Ng
at Stanford, and Nolan Goodnight at Virginia.  A number of students in
those classes gave particularly valuable feedback and sent bug reports and
bug fixes; we would especially like to thank Evan Parker and Phil Beatty.
A draft of the manuscript of this book was used in classes taught by Bill
Mark and Don Fussell at the University of Texas, Austin, and Raghu
Machiraju at Ohio State University; their feedback was invaluable, and we
are grateful for their adventurousness in incorporating this system into
their courses, even while it was still being edited and revised.

</p>
<p>Matt Pharr would like to acknowledge colleagues and co-workers in
rendering-related endeavors who have been a great source of education and
who have substantially influenced his approach to writing renderers and his
understanding of the field.  Particular thanks go to Craig Kolb, who
provided a cornerstone of Matt&rsquo;s early computer graphics education through
the freely available source code to the <tt>rayshade</tt> ray-tracing system,
and Eric Veach, who has also been generous with his time and expertise.
Thanks also to Doug Shult and Stan Eisenstat for formative lessons in
mathematics and computer science during high school and college,
respectively, and most important to Matt&rsquo;s parents, for the education they
have provided and continued encouragement along the way. Finally, thanks to
NVIDIA for supporting the preparation of both the first and this latest
edition of the book; at NVIDIA, thanks to Nick Triantos and Jayant Kolhe
for their support through the final stages of the preparation of the first
edition and thanks to Aaron Lefohn, David Luebke, and Bill Dally for their
support of work on the fourth edition.

</p>
<p>Greg Humphreys is very grateful to all the professors and TAs who tolerated
him when he was an undergraduate at Princeton.  Many people encouraged his
interest in graphics, specifically Michael Cohen, David Dobkin, Adam
Finkelstein, Michael Cox, Gordon Stoll, Patrick Min, and Dan Wallach.  Doug
Clark, Steve Lyon, and Andy Wolfe also supervised various independent
research boondoggles without even laughing once.  Once, in a group meeting
about a year-long robotics project, Steve Lyon became exasperated and
yelled, &ldquo;Stop telling me why it can&rsquo;t be done, and figure out how to do
it!&rdquo;&mdash;an impromptu lesson that will never be forgotten.  Eric Ristad
fired Greg as a summer research assistant after his freshman year (before
the summer even began), pawning him off on an unsuspecting Pat Hanrahan and
beginning an advising relationship that would span 10 years and both
coasts.  Finally, Dave Hanson taught Greg that literate programming was a
great way to work and that computer programming can be a beautiful and
subtle art form.

</p>
<p>Wenzel Jakob was excited when the first edition of <tt>pbrt</tt> arrived in his mail
during his undergraduate studies in 2004. Needless to say, this had a lasting
effect on his career&mdash;thus Wenzel would like to begin by thanking his
co-authors for inviting him to become a part of
the third and fourth editions of this book.
Wenzel is extremely indebted to Steve Marschner, who was his Ph.D. advisor during
a fulfilling five years at Cornell University. Steve brought him into the world
of research and remains a continuous source of inspiration. Wenzel is also
thankful for the guidance and stimulating research environment created by the
other members of the graphics group, including Kavita Bala, Doug James, and
Bruce Walter. Wenzel spent a wonderful postdoc with Olga Sorkine Hornung, who
introduced him to geometry processing. Olga&rsquo;s support for Wenzel&rsquo;s involvement
in the third edition of this book is deeply appreciated.

</p>
<p>We would especially like to thank the reviewers who read drafts in their
entirety; all had insightful and constructive feedback about the manuscript
at various stages of its progress.  For providing feedback on both the
first and second editions of the book, thanks to
Ian Ashdown, 
Per Christensen, 
Doug Epps, 
Dan Goldman, 
Eric Haines, 
Erik Reinhard, 
Pete Shirley,
Peter-Pike Sloan,
Greg Ward, and a host of anonymous reviewers.
For the second edition, thanks to
Janne Kontkanen,
Bill Mark,
Nelson Max,
and
Eric Tabellion.
For the fourth edition, we are grateful to Thomas M&uuml;ller and
Per Christensen, who both offered extensive feedback that has measurably
improved the final version.

</p>
<p>Many experts have kindly explained subtleties in their work to us and guided
us to best practices.  For the first and second editions, 
we are also grateful to Don Mitchell, for his help
with understanding some of the details of sampling and reconstruction;
Thomas Kollig and Alexander Keller, for explaining the finer points of
low-discrepancy sampling; Christer Ericson, who had a number of
suggestions for improving our kd-tree implementation; and
Christophe Hery and Eugene d&rsquo;Eon for helping us
with the nuances of subsurface scattering.

</p>
<p>For the third edition, we would especially like to thank
Leo Gr&uuml;nschlo&szlig; for reviewing our sampling chapter;
Alexander Keller for suggestions about topics for that chapter;
Eric Heitz for extensive help with details of microfacets and reviewing our text on
that topic;
Thiago Ize for thoroughly reviewing the text on floating-point error;
Tom van Bussel for reporting a number of errors in our BSSRDF code;
Ralf Habel for reviewing our BSSRDF text;
and Toshiya Hachisuka and Anton Kaplanyan for extensive review and comments
about our light transport chapters.

</p>
<p>For the fourth edition, thanks to
Alejandro Conty Estevez for reviewing our treatment of many-light sampling;
Eugene d&rsquo;Eon, Bailey Miller, and Jan Nov&aacute;k for comments on the
volumetric scattering chapters;
Eric Haines, Simon Kallweit, Martin Stich, and Carsten W&auml;chter for
reviewing the chapter on GPU rendering;
Karl Li for feedback on a number of chapters;
Tzu-Mao Li for his review of our discussion of inverse and differentiable rendering;
Fabrice Rousselle for feedback on machine learning and rendering;
and Gurprit Singh for comments on our discussion of Fourier analysis of
Monte Carlo integration.
We also appreciate extensive comments and suggestions from Jeppe Revall
Frisvad on <tt>pbrt</tt>&rsquo;s treatment of reflection models in previous editions.

</p>
<p>For improvements to <tt>pbrt</tt>&rsquo;s implementation in this edition, thanks to Pierre Moreau
for his efforts in debugging <tt>pbrt</tt>&rsquo;s GPU support on Windows and to Jim
Price, who not only found and fixed numerous bugs in the early release
of <tt>pbrt</tt>&rsquo;s source code, but who also contributed a better representation of
chromatic volumetric media than our original implementation.  We are also
very appreciative of Anders Langlands and Luca Fascione of Weta Digital
for providing an implementation of their <em>PhysLight</em> system, which has
been incorporated into <tt>pbrt</tt>&rsquo;s <tt>PixelSensor</tt> class and light source
implementations.

</p>
<p>Many people have reported errors in the text of previous editions or bugs
in <tt>pbrt</tt>. We&rsquo;d especially like to thank
Solomon Boulos,
Stephen Chenney,
Per Christensen,
John Danks, 
Mike Day,
Kevin Egan,
Volodymyr Kachurovskyi,
Kostya Smolenskiy,
Ke Xu, and
Arek Zimny,
who have been especially prolific.

</p>
<p>For their suggestions and bug reports, we would also like to thank 
Rachit Agrawal,
Frederick Akalin,
Thomas de Bodt,
Mark Bolstad,
Brian Budge,
Jonathon Cai,
Bryan Catanzaro,
Tzu-Chieh Chang,
Mark Colbert,
Yunjian Ding,
Tao Du,
Marcos Fajardo,
Shaohua Fan,
Luca Fascione,
Etienne Ferrier,
Nigel Fisher,
Jeppe Revall Frisvad,
Robert G. Graf,
Asbj&oslash;rn Heid,
Steve Hill,
Wei-Feng Huang,
John &ldquo;Spike&rdquo; Hughes,
Keith Jeffery,
Greg Johnson,
Aaron Karp,
Andrew Kensler,
Alan King,
Donald Knuth,
Martin Kraus,
Chris Kulla,
Murat Kurt,
Larry Lai,
Morgan McGuire,
Craig McNaughton,
Don Mitchell,
Swaminathan Narayanan,
Anders Nilsson,
Jens Olsson,
Vincent Pegoraro,
Srinath Ravichandiran,
Andy Selle,
S&eacute;bastien Speierer,
Nils Thuerey,
Eric Veach,
Ingo Wald,
Zejian Wang,
Xiong Wei,
Wei-Wei Xu, 
Tizian Zeltner,
and
Matthias Zwicker.
Finally, we would like to thank the <em>LuxRender</em> developers and
the <em>LuxRender</em> community, particularly
Terrence Vergauwen,
Jean-Philippe Grimaldi, and
Asbj&oslash;rn Heid; 
it has been a delight to see the rendering system they have built from <tt>pbrt</tt>&rsquo;s
foundation, and we have learned from reading their source code and
implementations of new rendering algorithms.

</p>
<p>Special thanks to Martin Preston and Steph Bruning from Framestore for
their help with our being able to use a frame from <em>Gravity</em> (image
courtesy of Warner Bros. and Framestore), and to Weta Digital for their
help with the frame from
<em>Alita: Battle Angel</em> (&copy; 2018 Twentieth Century
Fox Film Corporation, All Rights Reserved).

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h4>Production</h4><p>


</p>
<p>For the production of the first edition, we would also like to thank our
editor Tim Cox for his willingness to take on this slightly
unorthodox project and for both his direction and patience throughout the
process. We are very grateful to Elisabeth Beller (project manager), who
went well beyond the call of duty for the book; her ability to keep
this complex project in control and on schedule was remarkable, and we
particularly thank her for the measurable impact she had on the quality
of the final result. Thanks also to Rick Camp (editorial assistant) for his
many contributions along the way. Paul Anagnostopoulos and Jacqui Scarlott
at Windfall Software did the book&rsquo;s composition; their ability to take the
authors&rsquo; homebrew literate programming file format and turn it into
high-quality final output while also juggling the multiple unusual types of
indexing we asked for is greatly appreciated. Thanks also to Ken DellaPenta
(copyeditor) and Jennifer McClain (proofreader), as well as to Max Spector
at Chen Design (text and cover designer) and Steve Rath (indexer).

</p>
<p>For the second edition, we would like to thank Greg Chalson, who talked us
into expanding and updating the book; Greg also ensured that Paul
Anagnostopoulos at Windfall Software would again do the book&rsquo;s composition.
We would like to thank Paul again for his efforts in working with this
book&rsquo;s production complexity.  Finally, we would also like to thank Todd
Green, Paul Gottehrer, and Heather Scherer at Elsevier.

</p>
<p>For the third edition, we would like to thank Todd Green, who
oversaw that go-round, and Amy Invernizzi, who kept the train on the rails
throughout that process.  We were delighted to have Paul Anagnostopoulos at
Windfall Software part of this process for a third time; his efforts have
been critical to the book&rsquo;s high production value, which is so important to
us.

</p>
<p>The fourth edition saw us moving to MIT Press; many thanks to Elizabeth
Swayze for her enthusiasm for bringing us on board, guidance through the
production process, and ensuring that Paul Anagnostopoulos would again
handle composition.  Our deepest thanks to Paul for coming back for one more
edition with us, and many thanks as well to MaryEllen Oliver for her superb
work on copyediting and proofreading.

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h4>The Online Edition</h4><p>


</p>
<p>As of November 1, 2023, the full text of the fourth edition is available
online for free.  Many thanks to MIT Press and Elizabeth Swayze for their
support of a freely-available version of the book.

</p>
<p>A number of open source systems have been instrumental to the development
of the online version of <em>Physically Based Rendering</em>.  We&rsquo;d
specifically like to thank the developers of
<a href="https://getbootstrap.com">Bootstrap</a>,
<a href="https://jeri.io">JERI</a>,
<a href="https://www.mathjax.org">MathJax</a>, and
<a href="https://jquery.com/">JQuery</a>.  We&rsquo;d also like to thank
Impallari Type for the design of the
<a href="https://fonts.google.com/specimen/Domine">Domine</a> font that we use for body
text; Christian Robertson for the design of the <a href="https://fonts.google.com/specimen/Roboto+Mono">Roboto
Mono</a> font that we use for
code; and the designers
of the <a href="https://fontawesome.com/">Font Awesome</a> fonts.

</p>
<p>We&rsquo;d also like to thank everyone who supported the earlier online edition
through <em>Patreon</em>; as of 1 November 2023:
3Dscan,
Abdelhakim Deneche,
Alain Galvan,
Andr√©a Machizaud,
Aras Pranckevicius,
Arman Uguray,
Ben Bass,
Claudia Doppioslash,
Dong Feng,
Enrico,
Filip Strugar,
Haralambi Todorov,
Jaewon Jung,
Jan Walter,
Jendrik Illner,
Jim Price,
Joakim Dahl,
Jonathan Stone,
KrotanHill,
Laura Reznikov,
Malte Nawroth,
Mauricio Vives,
Mrinal Deo,
Nathan Vegdahl,
Pavel Panchekha,
Pratool Gadtaula,
Saad Ahmed,
Scott Pilet,
Shin Watanabe,
Steve Watts Kennedy,
Tom Hulton-Harrop,
Torgrim Boe Skaarsmoen,
William Newhall,
Yining Karl Li, and
Yury Mikhaylov.
We have, however, closed the <em>Patreon</em> with the launch of the fourth edition.

</p>
<p>Although the book is posted online for anyone to read for free, the text of
the book remains &copy; Copyright 2004&ndash;2023 Matt Pharr, Wenzel Jakob,
and Greg Humphreys under a <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">CC
BY-NC-ND 4.0</a> license.  The
book figures are licensed with a
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>
license with the thought that they may be useful when teaching graphics
courses.

</p>
<p>

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">
<a href="#"><i class="fas fa-link h3h4marginlink"></i></a>
</div>
<div class="col-md-10 col-lg-8">
<h4>Scenes, Models, and Data</h4><p>


</p>
<p>Many people and organizations have generously provided scenes
and models for use in this book and the <tt>pbrt</tt> distribution.  Their
generosity has been invaluable in helping us create interesting example
images throughout the text.

</p>
<p>We are most grateful to Guillermo M. Leal Llaguno of
Evoluci&oacute;n Visual, <a href="http://www.evvisual.com">www.evvisual.com</a>, who modeled and rendered the
iconic <em>San Miguel</em> scene that was featured on the cover of the second edition and
is still used in numerous figures in the book.  We would also especially
like to thank Marko Dabrovic (<a href="http://www.3lhd.com">www.3lhd.com</a>) and Mihovil Odak at RNA
Studios (<a href="http://www.rna.hr">www.rna.hr</a>), who supplied a bounty of models and
scenes used in earlier editions of the book, including the Sponza atrium,
the Sibenik cathedral, and the Audi TT car model that can be seen in
Figure&nbsp;<a href="Retrospective_and_the_Future/pbrt_over_the_Years.html#fig:tt-pbrt-v1-v4">16.1</a> of this edition.

Many thanks are also due to
Florent Boyer, who provided the contemporary house scene used in some of
the images in Chapter&nbsp;chap:bidir-methods.


</p>
<p>We sincerely thank Jan-Walter Schliep, Burak Kahraman, and Timm Dapper of
Laubwerk (<a href="http://www.laubwerk.com">www.laubwerk.com</a>) for creating the <em>Countryside</em>
landscape scene that was on the cover of the previous edition of the book
and is used in numerous figures in this edition.

</p>
<p>Many thanks to Angelo Ferretti of Lucydreams (<a href="http://www.lucydreams.it">www.lucydreams.it</a>) for
licensing the <em>Watercolor</em> and <em>Kroken</em> scenes, which have
provided a wonderful cover image for this edition, material for numerous
figures, and a pair of complex scenes that exercise <tt>pbrt</tt>&rsquo;s capabilities.

</p>
<p>Jim Price kindly provided a number of scenes featuring interesting
volumetric media; those have measurably improved the figures for that
topic.  Thanks also to Beeple for making the <em>Zero Day</em>
and <em>Transparent Machines</em> scenes available under a permissive license
and to Martin Lubich for the Austrian Imperial Crown model.  Finally, our
deepest thanks to Walt Disney Animation Studios for making the
production-complexity <em>Moana Island</em> scene available as well as
providing the detailed volumetric cloud model.

</p>
<p>The bunny, Buddha, and dragon models are courtesy of the Stanford Computer
Graphics Laboratory&rsquo;s scanning repository. The &ldquo;killeroo&rdquo; model is
included with permission of Phil Dench and Martin Rezard (3D scan and
digital representations by headus, design and clay sculpt by Rezard).  The
dragon model scan used in Chapter&nbsp;<a href="Reflection_Models.html#chap:reflection-models">9</a> is courtesy
of Christian Sch&uuml;ller, and our thanks to Yasutoshi Mori for the
material orb and the sports car model.

The glass used to illustrate caustics in Chapter&nbsp;chap:bidir-methods
is thanks to Simon Wendsche.

The head model used to illustrate subsurface scattering
was made available by Infinite Realities, Inc. under a Creative Commons
Attribution 3.0 license.  Thanks also to &ldquo;tyrant monkey&rdquo; for the BMW M6
car model and &ldquo;Wig42&rdquo; for the breakfast table scene; both were posted
to <a href="http://blendswap.com">blendswap.com</a>, also under a Creative Commons Attribution 3.0
license.

</p>
<p>We have made use of numerous environment maps from the <em>PolyHaven</em>
website (<a href="http://polyhaven.com">polyhaven.com</a>) for HDR lighting in various scenes; all are
available under a Creative Commons CC0 license.  Thanks to Sergej Majboroda
and Greg Zaal, whose environment maps we have used.

</p>
<p>Marc Ellens provided spectral data for a variety of light sources, and the
spectral RGB measurement data for a variety of displays is courtesy of Tom
Lianza at X-Rite.  Our thanks as well to Danny Pascale
(<a href="http://www.babelcolor.com">www.babelcolor.com</a>) for allowing us to include his measurements of
the spectral reflectance of a color chart.  Thanks to Mikhail Polyanskiy
for index of refraction data via <a href="http://refractiveindex.info">refractiveindex.info</a> and to Anders
Langlands, Luca Fascione, and Weta Digital for camera sensor response data
that is included in <tt>pbrt</tt>.

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

<div class="row">
<div class="col-md-1 col-lg-2 leftcolumn">

</div>
<div class="col-md-10 col-lg-8">
<h3>About The Cover</h3><p>


</p>
<p>The <em>Watercolor</em> scene on the cover was created by Angelo Ferretti of
Lucydreams (<a href="http://www.lucydreams.it">www.lucydreams.it</a>). It requires a total of 2 GiB of
on-disk storage for geometry and 836 MiB for texture maps. Come rendering,
the scene description requires 15 GiB of memory to store over 33 million
unique triangles, 412 texture maps, and associated data structures.

</p>
<p>

</p>
<p>

</p>
<p>
</p>

</div> <!-- col-md-10 col-lg-8 -->
<div class="col-md-1 col-lg-2">

</div> <!-- col-md-1 col-lg-2 -->
</div>  <!-- row -->

</div>  <!-- container-fluid -->
</div>  <!-- maincontainer -->

<nav class="navbar navbar-expand-md bg-light navbar-light">
<div class="container-fluid">
  <span class="navbar-text"><i>Physically Based Rendering: From Theory To Implementation</i>,<br>
<a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">&copy; 2004-2023</a> Matt Pharr, Wenzel Jakob, and Greg Humphreys.
<a href="https://github.com/mmp/pbr-book-website/"><span class="fab fa-github"></span></a><br>
Purchase a printed copy: <a href="https://www.amazon.com/Physically-Based-Rendering-fourth-Implementation/dp/0262048027?keywords=physically+based+rendering+4th+edition&qid=1671730412&sprefix=physically+based%!C(MISSING)aps%!C(MISSING)145&sr=8-1&linkCode=ll1&tag=pharr-20&linkId=81a816d90f0c7e872617f1f930a51fd6&language=en_US&ref_=as_li_ss_tl"><span class="fab fa-amazon"></span></a>
<a href="https://mitpress.mit.edu/9780262048026/physically-based-rendering/"><img src="/mitpress.png" width=10 height=16></a>
</span>
</div>
  <div class="container">
    <ul class="nav navbar-nav ml-auto">
      <li class="nav-item">Next: <a href="Preface/Further_Reading.html">Preface / Further Reading</a></li>
    </ul>
  </div>

</nav>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script>
  $(function () {
    $('[data-toggle="popover"]').popover()
    $('[data-toggle="tooltip"]').tooltip()
   })
</script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

<script>
// https://stackoverflow.com/a/17535094
// The function actually applying the offset
function offsetAnchor() {
  if (location.hash.length !== 0) {
    window.scrollTo(window.scrollX, window.scrollY - window.innerHeight / 8);
  }
}

// Captures click events of all <a> elements with href starting with #
$(document).on('click', 'a[href^="#"]', function(event) {
  // Click events are captured before hashchanges. Timeout
  // causes offsetAnchor to be called after the page jump.
  window.setTimeout(function() {
    offsetAnchor();
  }, 500);
});

// Set the offset when entering page with hash present in the url
window.setTimeout(offsetAnchor, 1500);
</script>

</body>
</html>
